## Hi there :v: ようこそ

My repositories here are tutorials (with Python code) for pre-processing Japanese text datasets for use with common analysis software:

* [Aozora Corpus Builder](https://github.com/mollydesjardin/aozora) for [Aozora Bunko](https://www.aozora.gr.jp/) HTML files
* [Taiyō Corpus Tools](https://github.com/mollydesjardin/taiyo-corpus-tools) for NINJAL's early-1900s [Taiyō magazine XML corpus](https://ccd.ninjal.ac.jp/cmj/taiyou/index.html)

The writeups are much longer than the code itself! I created them as a resource for getting started with the niche technical issues involved, just to get your data in compatible shape for most tools that aren't Japanese-specific. (Not-Unicode and no word boundaries are the main challenges.)

I no longer work in this area, so I'm sharing these as-is. _Please_ freely reuse, fork, adapt, and/or steal for your own purposes -- that's why it's here!


## Other resources

Each of the projects above has their own dataset-specific resource section, but you might be interested in other resources listed at my [East Asian Digital Humanities page](https://mollydesjardin.com/eadh/index.html) (external link): semester-long course syllabus, weekend workshop materials, and previous blog posts about the Aozora project. _It is not being actively updated, so be aware nothing is more recent than late 2019._

UPenn's [annual Dream Lab digital humanities workshop series](https://web.sas.upenn.edu/dream-lab/) has included [East Asian Digital Humanities](https://web.sas.upenn.edu/dream-lab/east-asian-studies-digital-humanities-2024/) for several years (co-taught by Paula Curtis and Paul Vierthaler). Paula has extensively taught Japanese text mining and digital methods in various workshops, and you can find more information on [her website](https://prcurtis.com/teaching/).

[Digital Humanities Japan](http://dhjapan.org) also maintains a wiki and mailing list to support resource-sharing and collaboration on Japanese-language digital projects and tech issues.
